{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "accessible-moses",
   "metadata": {},
   "source": [
    "# GANgster\n",
    "In this notebook we will try to generate mugshots with our generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-backing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from IPython import display\n",
    "\n",
    "import PIL\n",
    "import time\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-martin",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 64\n",
    "generator_entry = 50\n",
    "\n",
    "device = \"\"\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"running on GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"running on CPU\")\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,)), transforms.Resize((image_size, image_size)), transforms.Grayscale()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-squad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images_folder, transform=None):\n",
    "        self.df = []\n",
    "        for index, filepath in enumerate(glob.glob(f\"{images_folder}/*\")):\n",
    "            if index % 15 == 0:\n",
    "                filename = os.path.split(filepath)[1]\n",
    "                image = PIL.Image.open(f\"{images_folder}/{filename}\")\n",
    "                if transform is not None:\n",
    "                    image = transform(image)\n",
    "                self.df.append((image, filename))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.df[index]\n",
    "\n",
    "\n",
    "train_set = CustomDataset(\n",
    "    images_folder=\"../data/front/front\", transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-arthur",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set, batch_size=batch_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-activity",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "real_samples, real_labels = next(iter(train_loader))\n",
    "for i in range(16):\n",
    "    ax = plt.subplot(4, 4, i + 1)\n",
    "    ax.imshow(real_samples[i].reshape(image_size, image_size), cmap=\"gray\")\n",
    "    ax.set_title(real_labels[i], fontsize=12, pad=1.0)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-silver",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(image_size ** 2, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), image_size ** 2)\n",
    "        output = self.model(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-cinema",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator().to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-newport",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(generator_entry, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, image_size ** 2),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        output = output.view(x.size(0), 1, image_size, image_size)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-webmaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator().to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-tampa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.00001\n",
    "num_epochs = 20000\n",
    "show_every = 10\n",
    "loss_function = nn.BCELoss()\n",
    "\n",
    "print(\"DATASET SIZE :\", len(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-classics",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
    "optimizer_generator = torch.optim.Adam(generator.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-sally",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_x_time = []\n",
    "losses = {\n",
    "    \"generator\": [],\n",
    "    \"discriminator\": []\n",
    "}\n",
    "\n",
    "show_test_sample = torch.randn(1, generator_entry).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-reader",
   "metadata": {},
   "outputs": [],
   "source": [
    "evolution = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-amino",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epoch_start = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    loss_discriminator = 0\n",
    "    loss_generator = 0\n",
    "    for n, (real_samples, _) in enumerate(train_loader):\n",
    "        # Data for training the discriminator\n",
    "        \n",
    "        real_samples = real_samples.to(device=device)\n",
    "        real_samples_size = real_samples.shape[0]\n",
    "\n",
    "        # Set the labels of the real data to one (Using the size of the real samples array)\n",
    "        real_samples_labels = torch.ones((real_samples_size, 1)).to(device=device)\n",
    "\n",
    "        # Set the labels of the fake data to zero\n",
    "        latent_space_samples = torch.randn((real_samples_size, generator_entry)).to(device=device)\n",
    "        generated_samples = generator(latent_space_samples)\n",
    "        generated_samples_labels = torch.zeros((real_samples_size, 1)).to(device=device)\n",
    "\n",
    "        # Concatenate true and fake data\n",
    "        all_samples = torch.cat((real_samples, generated_samples))\n",
    "        all_samples_labels = torch.cat((real_samples_labels, generated_samples_labels))\n",
    "        \n",
    "        # Training the discriminator\n",
    "        discriminator.zero_grad()\n",
    "        output_discriminator = discriminator(all_samples)\n",
    "\n",
    "        loss_discriminator = loss_function(\n",
    "            output_discriminator, all_samples_labels\n",
    "        )\n",
    "        loss_discriminator.backward()\n",
    "        optimizer_discriminator.step()\n",
    "\n",
    "        # Data for training the generator\n",
    "        latent_space_samples = torch.randn((real_samples_size, generator_entry)).to(\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        # Training the generator\n",
    "        generator.zero_grad()\n",
    "        generated_samples = generator(latent_space_samples)\n",
    "        output_discriminator_generated = discriminator(generated_samples)\n",
    "        loss_generator = loss_function(\n",
    "            output_discriminator_generated, real_samples_labels\n",
    "        )\n",
    "        loss_generator.backward()\n",
    "        optimizer_generator.step()\n",
    "\n",
    "    # Show loss\n",
    "    if epoch % show_every == 0 and epoch != 0:\n",
    "        per_x_time.append(time.time() - epoch_start)\n",
    "        epoch_start = time.time()\n",
    "        losses[\"generator\"].append(float(loss_generator))\n",
    "        losses[\"discriminator\"].append(float(loss_discriminator))\n",
    "\n",
    "        ld = str(round(float(loss_discriminator), 10)).zfill(12)\n",
    "        lg = str(round(float(loss_generator), 10)).zfill(12)\n",
    "        it = str(round(per_x_time[-1], 4)).zfill(9)\n",
    "        av = str(round(sum(per_x_time)/len(per_x_time), 2)).zfill(6)\n",
    "        seconds = round(\n",
    "            ((sum(per_x_time)/len(per_x_time)) * ((num_epochs - epoch)/show_every)),\n",
    "            2\n",
    "        )\n",
    "        m, s = divmod(seconds, 60)\n",
    "        h, m = divmod(m, 60)\n",
    "        tl = \"%d:%02d:%02d\" % (h, m, s)\n",
    "        print(f\"[+] EPOCH : {str(epoch).zfill(7)} | LD.: {ld} | LG.: {lg} | IT : {it}s | AV : {av} | TL : {tl}\"\"\")\n",
    "        \n",
    "        generated_sample = generator(show_test_sample)\n",
    "        generated_sample = generated_sample.cpu().detach()\n",
    "        image = transforms.ToPILImage()(generated_sample[0].reshape(image_size, image_size))\n",
    "        evolution.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-planner",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"../models/{num_epochs}_{image_size}_{lr}\"\n",
    "\n",
    "x = 1\n",
    "while os.path.isdir(path):\n",
    "    path = f\"../models/{num_epochs}_{image_size}_{lr}_{x}\"\n",
    "    x += 1\n",
    "\n",
    "os.mkdir(path)\n",
    "\n",
    "torch.save(generator.state_dict, f\"{path}/generator\")\n",
    "torch.save(discriminator.state_dict, f\"{path}/discriminator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-mailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "evolution[0].save(f'{path}/progressive_text.gif', format='GIF',\n",
    "               append_images=evolution[1:], save_all=True, duration=75, loop=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-payday",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"avg_time\": round(sum(per_x_time)/len(per_x_time), 2),\n",
    "    \"total_time\": sum(per_x_time),\n",
    "    \"losses\": losses\n",
    "}\n",
    "\n",
    "with open(f\"{path}/meta.json\", 'w+') as f:\n",
    "    json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-fireplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_amount = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-bangkok",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "samples_to_try = torch.randn(samples_amount, generator_entry).to(device=device)\n",
    "generated_samples = generator(samples_to_try).cpu().detach()\n",
    "\n",
    "for i in range(samples_amount):\n",
    "    image = transforms.ToPILImage()(generated_samples[i].reshape(image_size, image_size))\n",
    "    display.display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-receiver",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
